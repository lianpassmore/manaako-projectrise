# Website Copy — Proofreading Document

All visible text from the live site, organised by page. Review for typos, tone, accuracy, and consistency.

---

## NAVIGATION (Layout — all pages)

**Header:**
- Wānanga 2026
- Mana Ako × Project Rise
- About the Research
- Book a person →
- Privacy & Data Rights *(mobile menu only)*

**Footer:**
- Research conducted by Lian Passmore & Lee Palamo
- Programme: Master of Technological Futures, AcademyEX
- Supervisors: Felix Scholz (Lian) & Paula Gair (Lee)
- Ethics: Approved under AcademyEX Research, Enterprise and Ethics (REE) process
- Lian: MTF.8888.275 (approved 21/07/2025 – 21/07/2027)
- Lee: Approval pending
- Questions? lianpassmore@gmail.com or leepalamo275@gmail.com
- Book a kōrero
- About the Research
- Privacy & Data Rights
- Your rights: You can withdraw at any time. Consent is ongoing. You can request deletion of your data. You can switch between AI and person at any point. Contact us anytime.

---

## PAGE 1: HOME (index.astro)

**Title:** When Culture Meets Conversational AI | Mana Ako x Project Rise

### Hero

# We need your voice.

We are two researchers building conversational AI tools for vulnerable spaces — one for te reo Māori learning, one for relationship support. We have reached a point in our work where we cannot answer the most important questions alone.

We are Lian and Lee. We are completing our Master of Technological Futures and we have both built conversational AI that people use in moments of vulnerability — when they are scared to speak te reo, or scared to open up about their relationships.

We have learned a lot. But the deeper we go, the bigger the questions get.

What does safety actually feel like when conversational AI holds a vulnerable conversation? Where are the cultural boundaries that technology should not cross? And who gets to decide?

We cannot figure this out from research papers. We need people — people who carry lived experience, cultural knowledge, and honest instincts about what feels right and what does not.

That is why we are inviting you to participate in a kōrero — on your terms — followed by an online wānanga where we explore these questions together.

**Button:** I'm in — show me how to take part

---

### Choose Your Path

**Label:** Choose Your Path

## Four ways to take part

There is no preferred option. Every path gives us what we need. Choose whatever feels right for you — and if you change your mind along the way, you can switch. You do not need to explain your choice.

**Card 1 — Talk to the AI**
Have a 10–15 minute voice conversation with a conversational AI using Lian's voice. It will explore safety, vulnerability, and what feels right when AI is involved in culturally significant spaces.
→ Start the AI conversation →

**Card 2 — Complete a written form**
Prefer to write? You can share your whakaaro in your own time through a written form. Your contribution is just as valuable as a spoken kōrero.
→ Go to the form →

**Card 3 — Kōrero with Lian or Lee**
Book a 30-minute conversation with a person. We will cover the same territory as the AI conversation, just human to human. This option is also available for anyone under 18.
→ Book 30 minutes →

**Card 4 — Not sure? We'll reach out**
Leave us your contact details and we will get in touch to figure out the best path for you — no pressure, no commitment.
→ Leave your details →

*You can change your mind at any point. If you start with the AI and decide you would rather talk to a person, we are here. If you start with a person and want to try the AI, the door is open. There is no wrong way to do this.*

---

### The Context

**Label:** The Context

## This is new ground.

There is research on data sovereignty. There is research on shame and safety in language learning. There is research on AI and Indigenous communities. But nobody has woven those together to ask:

> What happens when conversational AI holds a conversation that touches something sacred or vulnerable? What cultural obligations arise? And how do we design for that?

That is the gap — and your whakaaro helps fill it.

### What you will do

Have a kōrero — either with the AI (about 10–15 minutes using Lian's voice), with a person (about 30 minutes with Lian or Lee), or both. It will explore safety, vulnerability, and what feels right when conversational AI is involved in culturally significant spaces. It is not a test. There are no wrong answers. It is a kōrero.

Then, join us for a 90-minute online wānanga on **Thursday 26 February, 6.30pm to 8pm NZDT**, where we go deeper — together.

The wānanga is designed as a culturally grounded space to reflect on your experience. If you have the AI conversation in the same week, you will be able to sit with it while it is still fresh and explore what it brought up alongside others who have been through the same thing.

At the end of the wānanga, you will have the option to share any final reflections.

### What you will need

A quiet space, a device with a microphone, and about 15 minutes for the AI conversation (or 30 minutes for a person-to-person kōrero). The wānanga will be on Zoom.

---

### Timeline

**Label:** How This Works

## The Timeline

1. **Now — February 25** — Have your AI conversation (10–15 minutes, anytime that suits you) or book a kōrero with Lian or Lee.
2. **Thu 26 Feb, 6.30pm** — Online wānanga — we explore these questions together on Zoom. This is the space to reflect on your experience in a culturally grounded setting alongside others.
3. **After the wānanga** — Share your final reflections (5 minutes — AI or written form).
4. **Two weeks after** — Deadline to withdraw your data from the research if you change your mind.

---

### Why Online?

**Label:** A note on format

## Why online?

If we could get everyone in one room, we would. Kanohi ki te kanohi is always the first choice for this kind of mahi. But our participants are spread right across Aotearoa — from Tai Tokerau to Ōtautahi and everywhere in between — and two master's students do not come with a travel budget (if you know someone who wants to fund us, send them our way).

So we are doing what we can with what we have. We are building with the tools and skills available to us, and being as transparent and authentic as possible about what those tools can and cannot do. What we lack in resources we are making up for in care and honesty.

If this work grows beyond our theses — and we hope it does — the aspiration is always to be together in person. For now, this is where we start.

---

### The Details (Accordions)

## The Details

**Accordion: Lian Passmore**

Founder of DreamStorm, mum of five (including triplets), based in Whangārei. Samoan and NZ European. After 14 years in learning design, coaching, and organisational wellbeing, Lian kept seeing the same thing — people are not the problem, systems are. So she taught herself to build. Her master's project — Project Rise — explores how relational conversational AI can serve Māori, Pasifika, disabled, and digitally excluded communities, with one non-negotiable: build tech that serves people rather than extracts from them.

*Supervisor: Felix Scholz, AcademyEX*
*Cultural supervision: Monthly sessions with Māori and Pasifika advisors*

**Accordion: Lee Palamo**

Learning Experience Lead at Northpower, with a background in instructional design at Auckland Council and learning design at The Warehouse Group. Lee brings a designer's eye and a South Auckland sense of humour to everything she builds. Her master's project explores how conversational AI can support te reo Māori learners by providing a personalised, culturally grounded, and emotionally safe learning experience — creating space for people to practise te reo without the fear and shame that often accompanies learning in front of others.

*Supervisor: Paula Gair, AcademyEX*

**Accordion: Why we are working together**

Lian and Lee go way back. They first crossed paths when Lian was four or five — Lee went to school with her older sister. Fast forward twenty years and they found each other again as Learning Designers, battling it out for top spot at eLearning conference competitions year after year. That rivalry turned into a partnership when they worked together at Northpower for three to four years in the People and Capability team, and stood alongside each other as Kaitiaki in the peer support network.

Now they are doing their master's side by side — and the research landed in the same space. The people using Lee's app are scared — scared of making mistakes, of being judged, of not being Māori enough. The people using Lian's app are scared too — scared of being vulnerable, of opening up to a machine. The emotional terrain is the same. The cultural questions are the same. They are stronger exploring them together.

**Accordion: Infrastructure Transparency**

We believe in being upfront about our tools and their limitations. This research uses:

- ElevenLabs (US-based) for the conversational AI voice agent
- Supabase (hosted in Sydney, Australia) for our research database, with row-level security
- Zoom for the live wānanga

We do not own or control the AI infrastructure. The voice platform is built by a company based outside Aotearoa, governed by US law, with data stored on US servers. We have opted out of our data being used for AI model training, but ElevenLabs' Terms of Service include a broad license on data processed through their platform.

We chose these tools because building our own voice AI infrastructure was beyond our resources as two master's students working across Aotearoa. Te Hiku Media — who built their own speech recognition for te reo Māori — have shown what full sovereignty looks like. We are not there. We are honest about that, and the tension between our principles and our tools is part of what this research examines.

Full details are provided in the consent section before you begin the conversation.

---

### Final CTA

## Ready to kōrero?

**Button 1:** Start the AI conversation
**Button 2:** Book a kōrero with a person

---
---

## PAGE 2: ABOUT THE RESEARCH (about.astro)

**Title:** About the Research | Mana Ako x Project Rise

# The full picture

This page exists for anyone who wants to understand the research foundations behind this wānanga. You do not need to read any of this to participate — the landing page has everything essential. But if you are an academic, a practitioner, or just someone who likes to know the full story, here it is.

---

### Our Research Questions

**Label:** Our Research Questions

**Lian's main question**

*How might we design ethical conversational AI for vulnerable interactions using Māori and Pasifika values to protect marginalised communities?*

Sub-questions (using Dr Kiri Dell's compass framework):
- **Kei raro (Foundations):** What systemic barriers silence vulnerable voices in digital spaces?
- **Kei mua (Values):** How do Māori and Pasifika values translate into AI design decisions?
- **Kei runga (Purpose):** What purpose does ethical AI serve for vulnerable communities?
- **Kei roto (Agency):** How do we protect data sovereignty, safety, and dignity?
- **Kei waho (Innovation):** How do we develop this ethically with cultural governance?

**Lee's main question**

*How might conversational AI support te reo Māori learners by providing a personalised, culturally grounded, and emotionally safe learning experience?*

Sub-questions:
- How might AI help foster a safe, non-judgemental community of practice where learners can build confidence, connect with others, and explore te reo Māori together?
- What impact does using a conversational AI have on learners' confidence, motivation, and willingness to kōrero in te reo Māori?
- How might personalisation through AI and interactive learning design support motivation and a deeper connection to te reo Māori?

---

### The Literature

**Label:** The Literature

## What the literature tells us — and where it runs out

Our work is informed by Indigenous data sovereignty research (Te Mana Raraunga, Taiuru, Kukutai and Taylor), te reo revitalisation research (Keegan, Te Ataarangi, He rongoā tō te reo), and Indigenous AI development (Te Hiku Media, Running Wolf's FLAIR initiative).

The literature gives us strong frameworks for data governance and sovereignty. It shows us how whakamā, hopo, and intergenerational language trauma create barriers that are emotional and spiritual, not just educational. It shows us models like Te Hiku Media who built their own AI infrastructure from the ground up to maintain complete sovereignty.

But nobody has yet asked what happens at the intersection: when the tool that might strip cultural knowledge of its sacredness is also the tool that creates safe space for people carrying shame to engage with that knowledge.

> That is the paradox we are sitting in. That is what this wānanga explores.

---

### Methodology

**Label:** Methodology

This wānanga sits within a Participatory Action Research methodology. You are not a research subject — you are a co-researcher. Your whakaaro does not just inform our findings; it shapes the framework itself.

Both projects operate under kaupapa Māori research principles with regular cultural supervision.

---

### Infrastructure Transparency

**Label:** Infrastructure Transparency

We believe in being upfront about our tools and their limitations. This research uses:

- ElevenLabs (US-based) for the conversational AI voice agent
- Supabase (hosted in Sydney, Australia) for our research database, with row-level security
- Zoom for the live wānanga

We do not own or control the AI infrastructure. The voice platform is built by a company based outside Aotearoa, governed by US law, with data stored on US servers. We have opted out of our data being used for AI model training, but ElevenLabs' Terms of Service include a broad license on data processed through their platform.

We chose these tools because building our own voice AI infrastructure was beyond our resources as two master's students working across Aotearoa. Te Hiku Media — who built their own speech recognition for te reo Māori — have shown what full sovereignty looks like. We are not there. We are honest about that, and the tension between our principles and our tools is part of what this research examines.

Full details are provided in the consent section before you begin the conversation.

**Links:** ← Back to Home | Start the AI conversation → | Book a kōrero with a person →

---
---

## PAGE 3: BOOK A PERSON (human.astro)

**Title:** Talk to Lian or Lee | Mana Ako x Project Rise

# Prefer to kōrero with a person? No problem.

Not everyone wants to talk to an AI, and that is completely fine — it is actually useful data for our research to know that too. There is no preferred option. Every path contributes equally.

You can book a 30-minute conversation with Lian or Lee instead. We will cover the same territory as the AI conversation, just human to human.

This option is also available for anyone under 18 who wants to participate.

If you have already had a kōrero with a person and want to try the AI conversation as well, you are welcome to do that too.

### How this works

- We will cover the same territory as the AI conversation, just human to human.
- This option is available for anyone, including those under 18.
- After your kōrero, you will receive the same wānanga invitation as everyone else.
- If you have already had the AI conversation, this is a great way to go deeper or debrief.

*[Google Calendar booking embed]*

**Links:** ← Back to Home | Try the AI conversation instead →

---
---

## PAGE 4: PRIVACY & DATA SOVEREIGNTY (privacy.astro)

**Title:** Privacy & Data Sovereignty | Mana Ako x Project Rise

# Privacy & Data Sovereignty

**We are researching data sovereignty while using platforms we do not control. This page explains exactly how we manage that tension.**

---

### Two Layers of Data Control

There are two separate systems handling your data, each with different controls.

**Layer A: The Research (Lian and Lee)**

We control how your conversation content is used for research purposes — what gets analysed, how it is stored in Supabase, and how findings are shared. Your registration details and the transcripts we download for analysis are stored in Supabase (hosted in Sydney, Australia, AWS ap-southeast-2) with Row-Level Security ensuring your data is isolated and protected. You can ask us to delete your research data at any time.

**Layer B: The Technology (ElevenLabs)**

ElevenLabs (USA) processes the voice conversation. When you speak to the AI agent, your voice and words are sent to their servers in the United States. By using the AI agent, your data is subject to their Terms of Service, which grants them a broad, perpetual license to use conversation data to provide and improve their services.

We have opted out of ElevenLabs using your data for AI model training. However, we cannot revoke their standard processing license. ElevenLabs also reserves the right to moderate conversations for safety purposes, which means their staff or contractors may access your conversation content.

---

### Where your data goes

- **Registration data:** Supabase (Sydney, Australia)
- **Voice audio & transcripts:** ElevenLabs (United States)
- **Research transcripts:** Supabase (Sydney, Australia) — our separate copy
- **Live wānanga:** Zoom (US servers)

---

### Data Retention

- We will delete our copy of your transcript within 3 years of project completion, or earlier at your request.
- ElevenLabs retains voice data for up to 3 years after last interaction — we cannot control their retention or use of data already processed through their platform.

---

### Your Rights

- Participation is completely voluntary — and consent is ongoing, not a one-time decision.
- You can stop the conversation at any time — just close the browser.
- You can switch from the AI to a person, or from a person to the AI, at any point.
- You can withdraw your data from our research database up to two weeks after the wānanga by emailing us.
- You can participate in the AI conversation without attending the wānanga, or vice versa.
- You must be 18 or older to use the AI agent.
- If you are under 18 or prefer not to use AI, you can book a conversation with us directly.
- Choosing not to participate has no consequences whatsoever.

*Note: We can delete our copy of your transcript, but we cannot force ElevenLabs to delete their processing logs. You have separate rights under their Terms of Service.*

---

### Who will see your responses

Lian and Lee (the researchers), and our academic supervisors (Felix Scholz and Paula Gair). Cultural advisors may review de-identified themes. Your name will not appear in any published work unless you specifically request attribution.

---

### Why we are being this direct

We are researching data sovereignty while using a platform we do not control, hosted in a country with different privacy laws than Aotearoa. The terms of that platform do not align with the Indigenous data sovereignty principles our research is built on. We chose it because building our own voice AI was beyond our capacity, and we believe this research needs to happen now rather than waiting for perfect infrastructure.

You deserve to know exactly what you are agreeing to. This contradiction is real, and it is one of the things we are exploring in this research. What we lack in resources, we are making up for in honesty.

---

### Contact

Questions about your data? Email lianpassmore@gmail.com or leepalamo275@gmail.com

**Link:** ← Return Home

---
---

## PAGE 5: FINAL REFLECTIONS (reflections.astro)

**Title:** Final Reflections | Mana Ako x Project Rise

# Final reflections

You have just spent 90 minutes in kōrero with a room full of people thinking deeply about these questions. Before you go, we would love to capture where you have landed.

You can either talk to the AI again (same voice, shorter conversation — about 5 minutes) or fill in a written form below. Whatever feels right.

**Tabs:** Talk to the AI | Write your reflections

### Talk Mode

## Kōrero with Ray (Reflection Mode)

This is a shorter conversation (about 5 minutes) to capture your immediate thoughts.

### Write Mode (Reflection Form)

**Form fields:**

- **Your Email** (so we can link this to your registration) — *Placeholder: The one you used to register*
- **Did anything shift for you between the private AI conversation and the group wānanga?**
- **Was there anything you shared with the AI that you would not have said in the room — or something that came up in the room that you would not have told the AI?**
- **Having experienced both, what feels right about conversational AI in vulnerable spaces — and what does not?**
- **Would you use something like this again?** — Yes / No / Maybe
- **Would you recommend this experience to someone you care about?** — Yes / No / Maybe
- **Anything else you want us to know?**

**Button:** Submit Reflections

**Success message:**
Ngā mihi nui.
Your reflections have been safely received.
We will send the summary insights to you soon.

**Error message:** Unable to save your reflections. Please try again.

---
---

## PAGE 6: PARTICIPATE (participate.astro + ParticipationFlow component)

**Title:** Participate | Mana Ako x Project Rise

# Join the Kōrero

Register, Consent, and Speak.

---

### Step 1: Your Details

**Progress:** 1. Details → 2. Consent → 3. Prepare → 4. Kōrero

Kia ora — before we begin, we need a few details. This takes about 60 seconds.

- **First Name \*** — *Placeholder: Enter your first name*
- **Last Name \*** — *Placeholder: Enter your last name*
- **Email Address \*** — *Placeholder: you@example.com*
  - *This is how we will send your wānanga invitation.*
- **Which best describes you?** — Select... / Te reo Māori learner / Te reo Māori speaker or practitioner / Educator or kaiako / Kaupapa Māori practitioner / Technology or AI professional / Researcher or academic / Community member / Other
- **Which cultural identities do you connect with?** — *Placeholder: e.g. Māori, Samoan, Pākehā...*
- **Age Range** — Select... / 18–24 / 25–34 / 35–44 / 45–54 / 55–64 / 65+
- **Where in Aotearoa are you based?** — *Placeholder: e.g. Hamilton, Tai Tokerau*

*These details help us understand who is in the room. They are optional — share what feels comfortable. Nothing here affects your ability to participate.*

**Button:** Next Step: Consent

**Error:** Please fill in the required fields (Name & Email).

---

### Step 2: Consent

Consent

Before we start the kōrero, please read through the following and confirm you are comfortable to proceed. Consent is not a one-time gate — it is ongoing. You can change your mind about any part of your participation at any time, no questions asked.

#### WHAT THIS INVOLVES

You will have a 10 to 15 minute voice conversation with a conversational AI agent. It uses Lian's voice and will ask you about safety, vulnerability, and cultural considerations around conversational AI. After the conversation, you will be invited to an online wānanga on Thursday 26 February, 6.30pm to 8pm NZDT, where we explore these themes as a group.

If at any point during the AI conversation you would prefer to talk to a person instead, you can stop and book a kōrero with Lian or Lee. The same applies in reverse — if you start with a person and want to try the AI, you can.

#### ABOUT THE AI

Before you begin, we want to be upfront about what you are talking to.

This is a conversational AI. It uses Lian's voice, but it is not Lian. It is not a person, a teacher, a therapist, or an authority on anything. It is a tool — and like all tools, it has limitations.

The AI can make mistakes. It may misunderstand what you say, respond in ways that do not quite fit, or miss nuance that a person would catch. It does not hold cultural knowledge the way a person does. It cannot read your body language or your silence. It does not remember you between sessions.

We are not presenting it as something it is not. Part of what this research explores is exactly where AI works and where it falls short — and your experience of those edges is some of the most valuable data we will collect.

#### HOW YOUR KŌRERO IS PROCESSED

When you speak to the AI agent, your voice and words are processed by ElevenLabs, a US-based voice AI company. Your conversation is sent to their servers in the United States to generate the AI response and create a transcript. All data is transferred to and stored in the United States, regardless of your location.

We have opted out of ElevenLabs using your data for AI model training. However, by using the agent, your conversation is subject to ElevenLabs' Terms of Service, which grants them a broad, perpetual license to use conversation data to provide and improve their services. We cannot revoke this license after the fact. You can read their full terms at elevenlabs.io/terms-of-use.

ElevenLabs also reserves the right to moderate conversations for safety purposes, which means their staff or contractors may access your conversation content. The AI does not retain memory between sessions — it will not remember you if you come back.

Your conversation will not be used to train any AI model. Your words stay as your words — they do not become part of how this or any other AI learns.

#### HOW WE USE YOUR KŌRERO

We separately store your conversation transcript in our own research database (Supabase, hosted in Sydney, Australia) with row-level security ensuring your data is isolated and protected. Your insights will be analysed as part of both Lian's and Lee's master's research projects at AcademyEX.

#### TWO LAYERS OF DATA CONTROL

There are two separate systems handling your data, each with different controls.

Lian and Lee control how your conversation content is used for research purposes — what gets analysed, how it is stored in Supabase, and how findings are shared. You can ask us to delete your research data at any time.

ElevenLabs controls the technical processing and storage of your voice recordings on their platform. Their retention and usage policies are governed by their own Terms of Service.

Our research protocols are separate from ElevenLabs' platform policies. You have rights under both.

#### WHO WILL SEE YOUR RESPONSES

Lian and Lee (the researchers), and our academic supervisors (Felix Scholz and Paula Gair). Cultural advisors may review de-identified themes. Your name will not appear in any published work unless you specifically request attribution.

#### WHY WE ARE BEING THIS DIRECT

We are two master's students with participants spread across Aotearoa. Our first choice would always be kanohi ki te kanohi — face to face. But geography and funding mean that is not possible right now, so we are using the best tools available to us and being completely transparent about what those tools can and cannot do.

We are researching data sovereignty while using a platform we do not control, hosted in a country with different privacy laws than Aotearoa. The terms of that platform do not align with the Indigenous data sovereignty principles our research is built on. We chose it because building our own voice AI was beyond our capacity, and we believe this research needs to happen now rather than waiting for perfect infrastructure.

You deserve to know exactly what you are agreeing to. This contradiction is real, and it is one of the things we are exploring in this research. What we lack in resources, we are making up for in honesty.

#### YOUR RIGHTS

- Participation is completely voluntary — and consent is ongoing, not a one-time decision
- You can stop the conversation at any time — just close the browser
- You can switch from the AI to a person, or from a person to the AI, at any point
- You can withdraw your data from our research database up to two weeks after the wānanga by emailing us
- We will delete our copy of your transcript within 3 years of project completion, or earlier at your request
- ElevenLabs retains voice data for up to 3 years after last interaction — we cannot control their retention or use of data already processed through their platform
- You can participate in the AI conversation without attending the wānanga, or vice versa
- You must be 18 or older to use the AI agent
- If you are under 18 or prefer not to use AI, you can book a conversation with us directly instead
- Choosing not to participate has no consequences whatsoever

#### WHAT IS IN IT FOR YOU

You are helping build something that does not exist yet — a culturally grounded framework for how conversational AI should behave in vulnerable spaces. After the wānanga, we will share what we learned with all participants. Your insights directly shape how these tools are designed.

#### IF SOMETHING COMES UP

These conversations can touch on personal experiences of vulnerability, shame, or cultural harm. If anything feels uncomfortable, you are welcome to stop at any time. You do not need to explain why.

If you would like to talk to someone:

**Mental Health Support**
- 1737 — free call or text, anytime (24/7)
- Lifeline — 0800 543 354

**Domestic Violence**
- Women's Refuge — 0800 733 843

**Emergency**
- 111

Lian and Lee are also available if you want to debrief: lianpassmore@gmail.com or leepalamo275@gmail.com

---

**Consent checkboxes:**

1. ☐ I understand what this research involves and how my data will be processed, including by ElevenLabs under their Terms of Service
2. ☐ I understand my conversation will be recorded, transcribed, and stored for research purposes
3. ☐ I understand my participation is voluntary, consent is ongoing, and I can withdraw at any time
4. ☐ I understand the AI is a tool with limitations — it is not a person, teacher, or authority
5. ☐ I consent to my insights being used in Lian Passmore's and Lee Palamo's master's research at AcademyEX
6. ☐ I confirm I am 18 years or older
7. ☐ I am ready to begin

*By proceeding, you are giving informed consent as described above. You can revisit or change your mind about any part of this at any time. If you have any questions before starting, email lianpassmore@gmail.com or leepalamo275@gmail.com, or book a kōrero with us.*

**Button:** I Agree — Continue

**Error:** Please confirm all consent checkboxes to proceed.

---

### Step 3: Before You Begin (Pause Screen)

# Before you begin.

#### Honouring the space

This kōrero may touch on things that sit close to the heart — identity, culture, vulnerability, shame. For some people, this kind of conversation naturally sits in a space that deserves care.

If it feels right for you, you are welcome to take a moment before you start — whether that is a karakia, a quiet breath, or simply checking in with yourself. There is no right or wrong way to enter this space. How you begin and end is entirely yours.

#### What you are walking into

In a moment, you will hear Lian's voice. But it is not Lian — it is a conversational AI using her voice. It will introduce itself and guide the conversation. You do not need to prepare anything.

The AI is a tool. It can make mistakes, miss nuance, or respond in ways that feel off. That is okay — noticing those moments is part of what makes your experience valuable to this research.

#### What to notice

As you talk, pay attention to how it feels. Notice where trust forms or breaks down. Notice where the AI feels helpful — and where it feels unsafe or insufficient. You do not need to analyse this in the moment. Just let yourself notice.

This works best in a quiet space with headphones. The conversation runs about 10 to 15 minutes. You can say as much or as little as you like. There are no wrong answers — we are exploring, not testing.

#### If you want to stop

If you want to stop at any time, just close the page. If you decide you would rather talk to a person instead, you can reach Lian or Lee at lianpassmore@gmail.com or leepalamo275@gmail.com, or book a time.

**Button:** Start the kōrero

---

### Step 4: Kōrero (Conversation Screen)

## Kōrero with Ray

Click the microphone to start. Speak naturally. When you are finished, click "End Conversation".

**Link:** I have finished the conversation →

---

### Step 5: Post-Conversation

## Ngā mihi — thank you.

Your kōrero matters. What you have just shared will help shape how we think about designing conversational AI for vulnerable spaces.

#### Before you go — two quick questions

- **Would you use something like this again?** — Yes / No / Maybe
- **Would you recommend this experience to someone you care about?** — Yes / No / Maybe
- **Is there anything else sitting with you right now?** *(Optional)*

**Button:** Submit

#### What happens next

Check your email — we have sent you an invitation to the online wānanga on Thursday 26 February, 6.30pm to 8pm NZDT. That is where we take everything that has been shared in these individual conversations and explore it together as a group. The wānanga is a culturally grounded space to sit with what came up and make sense of it alongside others.

You will also receive a reminder the day before, and an hour before we start.

#### Want to switch paths?

If that conversation made you want to talk to a person, you can book a kōrero with Lian or Lee anytime.
→ Book a kōrero →

Can't make the wānanga? That is okay. Your conversation still contributes to the research and we value it. We will send you a summary of what we learned after the wānanga.

Want to talk to us? If anything came up during the conversation that you would like to discuss — or if you just want to say hi before the wānanga — reach out anytime: lianpassmore@gmail.com or leepalamo275@gmail.com

**Link:** Return to Home

---
---

## CRISIS SUPPORT MODAL (all pages)

**Trigger:** Need Support? (!)

### Support Resources

These conversations can touch on personal experiences of vulnerability, shame, or cultural harm. If anything feels uncomfortable, you are welcome to stop at any time.

**Mental Health Support**
- 1737 — Free call or text, anytime (24/7)
- Lifeline — 0800 543 354

**Domestic Violence**
- Women's Refuge — 0800 733 843

**Emergency**
- 111

Lian and Lee are also available if you want to debrief: lianpassmore@gmail.com or leepalamo275@gmail.com

**Button:** Return to Website
