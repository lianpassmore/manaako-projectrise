# Website Copy — Live Site (as at 12 Feb 2026)

All visible text extracted from the current codebase. Organised by page.

---

## NAVIGATION (Layout.astro — all pages)

**Header:**
- Wānanga 2026
- Mana Ako × Project Rise
- About the Research
- Participate →
- Privacy & Data Rights *(mobile menu only)*

**Footer:**
- Research conducted by Lian Passmore & Lee Palamo
- Programme: Master of Technological Futures, AcademyEX
- Supervisors: Felix Scholz (Lian) & Paula Gair (Lee)
- Ethics: Approved under AcademyEX Research, Enterprise and Ethics (REE) process
- Lian: MTF.8888.275 (approved 21/07/2025 – 21/07/2027)
- Lee: MTF.8888.274 (approved 21/07/2025 – 21/07/2027)
- Questions? lianpassmore@gmail.com or leepalamo275@gmail.com
- Book a kōrero
- About the Research
- Privacy & Data Rights
- Your rights: You can withdraw at any time. Consent is ongoing. You can request deletion of your data. You can switch between AI and person at any point. Contact us anytime.
- Designed and powered by YourHQ

---

## PAGE 1: HOME (index.astro)

**Title:** When Culture Meets Conversational AI | Mana Ako x Project Rise

### Hero

# We need your voice.

Two researchers. Two AI tools built for vulnerable spaces. One question we can't answer alone: **what does safety actually feel like when AI holds a conversation that matters?**

**Button:** I'm in →

---

### What is this?

## What is this?

We're Lian and Lee — two master's students who've built conversational AI for relationship support and te reo Māori learning. We've reached the questions we can't answer from research papers. We need people with lived experience and honest instincts.

---

### Four Ways to Take Part

## Four ways to take part

Pick whatever feels right. You can switch anytime.

**Card 1 — Talk to the AI**
10–15 min voice conversation using Lian's voice.
→ Start →

**Card 2 — Fill in a form**
Share your thoughts in writing, in your own time.
→ Go to form →

**Card 3 — Talk to a person**
30 min kōrero with Lian or Lee. Also available for under 18s.
→ Book →

**Card 4 — Not sure yet**
Leave your details and we'll reach out.
→ Leave details →

---

### Then we come together.

## Then we come together.

**Thursday 26 Feb, 6.30–8pm NZDT** — Online wānanga on Zoom. We take what came up in individual kōrero and explore it as a group.

Can't make it? Your individual conversation still counts.

---

### The Timeline

## The timeline

1. **Now – 25 Feb** — Have your kōrero (AI, form, or person)
2. **Thu 26 Feb, 6.30pm** — Online wānanga together
3. **After** — Share final reflections (5 min)
4. **Two weeks later** — Last chance to withdraw your data

---

### What you'll need

## What you'll need

A quiet space, a device with a mic, and about 15 minutes. The wānanga is on Zoom.

---

### Why online?

## Why online?

Our participants are across Aotearoa, and two master's students don't come with a travel budget. We're being honest about what we can and can't do — and that honesty is part of the research.

---

### Final CTA

## Ready?

**Button 1:** Start the AI conversation →
**Button 2:** Book a kōrero with a person →

---

### Footer Links

- Want the full picture? → About the Research
- How your data is handled → Privacy & Data

---
---

## PAGE 2: ABOUT THE RESEARCH (about.astro)

**Title:** About the Research | Mana Ako x Project Rise

# The full picture

You don't need any of this to participate. But if you want to understand the research foundations, here they are.

---

### Our Research Questions

## Our research questions

**Lian**

*How might we design ethical conversational AI for vulnerable interactions using Māori and Pasifika values?*

Sub-questions (Kiri Dell's compass framework):
- **Kei raro (Foundations):** What systemic barriers silence vulnerable voices in digital spaces?
- **Kei mua (Values):** How do Māori and Pasifika values translate into AI design decisions?
- **Kei runga (Purpose):** What purpose does ethical AI serve for vulnerable communities?
- **Kei roto (Agency):** How do we protect data sovereignty, safety, and dignity?
- **Kei waho (Innovation):** How do we develop this ethically with cultural governance?

**Lee**

*How might conversational AI support te reo Māori learners with a culturally grounded, emotionally safe experience?*

Sub-questions:
- How might AI help foster a safe, non-judgemental community of practice where learners can build confidence, connect with others, and explore te reo Māori together?
- What impact does using a conversational AI have on learners' confidence, motivation, and willingness to kōrero in te reo Māori?
- How might personalisation through AI and interactive learning design support motivation and a deeper connection to te reo Māori?

---

### The Gap

## The gap

There's research on data sovereignty. Research on shame in language learning. Research on AI and Indigenous communities. Nobody has woven them together to ask: **what happens when AI holds a conversation that touches something sacred?**

---

### Methodology

## Methodology

Participatory Action Research. You're a co-researcher, not a subject. Both projects operate under kaupapa Māori research principles with cultural supervision.

---

### Who We Are

## Who we are

**Lian Passmore**
Samoan and NZ European. Mum of five. Based in Whangārei. 14 years in learning design. Taught herself to build. Her project (Project Rise) explores relational conversational AI for marginalised communities.
*Supervisor: Felix Scholz. Monthly cultural supervision.*

**Lee Palamo**
Learning Experience Lead at Northpower. South Auckland roots. Her project explores conversational AI for te reo Māori learners — creating space to practise without fear or shame.
*Supervisor: Paula Gair.*

**Accordion: Why we're working together**

Lian and Lee go way back. They first crossed paths when Lian was four or five — Lee went to school with her older sister. Fast forward twenty years and they found each other again as Learning Designers, battling it out for top spot at eLearning conference competitions year after year. That rivalry turned into a partnership when they worked together at Northpower for three to four years in the People and Capability team, and stood alongside each other as Kaitiaki in the peer support network.

Now they are doing their master's side by side — and the research landed in the same space. The people using Lee's app are scared — scared of making mistakes, of being judged, of not being Māori enough. The people using Lian's app are scared too — scared of being vulnerable, of opening up to a machine. The emotional terrain is the same. The cultural questions are the same. They are stronger exploring them together.

**Accordion: Our tools and their limitations**

We believe in being upfront about our tools and their limitations. This research uses:

- ElevenLabs (US-based) for the conversational AI voice agent
- Supabase (hosted in Sydney, Australia) for registration data, with row-level security
- Zoom for the live wānanga

We do not own or control the AI infrastructure. The voice platform is built by a company based outside Aotearoa, governed by US law, with data stored on US servers. We have opted out of our data being used for AI model training, but ElevenLabs' Terms of Service include a broad license on data processed through their platform.

We chose these tools because building our own voice AI infrastructure was beyond our resources as two master's students working across Aotearoa. Te Hiku Media — who built their own speech recognition for te reo Māori — have shown what full sovereignty looks like. We are not there. We are honest about that, and the tension between our principles and our tools is part of what this research examines.

**Links:** ← Home | Start the AI conversation → | Book a person →

---
---

## PAGE 3: BOOK A PERSON (human.astro)

**Title:** Talk to Lian or Lee | Mana Ako x Project Rise

# Prefer to kōrero with a person? No problem.

Not everyone wants to talk to an AI, and that is completely fine — it is actually useful data for our research to know that too. There is no preferred option. Every path contributes equally.

You can book a 30-minute conversation with Lian or Lee instead. We will cover the same territory as the AI conversation, just human to human.

This option is also available for anyone under 18 who wants to participate.

If you have already had a kōrero with a person and want to try the AI conversation as well, you are welcome to do that too.

### How this works

- We will cover the same territory as the AI conversation, just human to human.
- This option is available for anyone, including those under 18.
- After your kōrero, you will receive the same wānanga invitation as everyone else.
- If you have already had the AI conversation, this is a great way to go deeper or debrief.

*[Google Calendar booking embed]*

**Links:** ← Back to Home | Try the AI conversation instead →

---
---

## PAGE 4: PRIVACY & DATA (privacy.astro)

**Title:** Privacy & Data | Mana Ako x Project Rise

# Your data, honestly.

We're researching data sovereignty while using platforms we don't control. Here's exactly how that works.

---

### Two systems handle your data

**What we control (the research)**
Your registration details are stored in Supabase (Sydney, AU) with row-level security. Transcripts stay in ElevenLabs — we download them from there for analysis. You can ask us to delete your registration data anytime.

**What we don't control (the tech)**
ElevenLabs (US) processes your voice. Your audio goes to US servers. We've opted out of model training, but their Terms of Service grant a broad license. We can't revoke that after the fact.

---

### Where your data goes

| Data | Where |
|------|-------|
| Registration | Supabase (Sydney) |
| Voice & transcript | ElevenLabs (US) |
| Transcripts (downloaded for analysis) | ElevenLabs (US) |
| Wānanga | Zoom (US) |

---

### Your rights

- Stop anytime — close the browser
- Switch between AI and person whenever
- Withdraw from our database up to two weeks after wānanga
- We delete our copy within 3 years (or earlier on request)
- ElevenLabs retains up to 3 years — we can't control that
- Must be 18+ for the AI; under 18 can book a person
- Not participating has zero consequences

---

### Why we're being this direct

The tools we're using don't align with the data sovereignty principles our research is built on. We chose them because building our own voice AI was beyond our capacity. That contradiction is real — and it's one of the things this research explores.

---

### Contact

lianpassmore@gmail.com · leepalamo275@gmail.com

**Link:** ← Home

---
---

## PAGE 5: FINAL REFLECTIONS (reflections.astro)

**Title:** Final Reflections | Mana Ako x Project Rise

# Final reflections

You have just spent 90 minutes in kōrero with a room full of people thinking deeply about these questions. Before you go, we would love to capture where you have landed.

You can either talk to the AI again (same voice, shorter conversation — about 5 minutes) or fill in a written form below. Whatever feels right.

**Tabs:** Talk to the AI | Write your reflections

### Talk Mode

## Kōrero with Ray (Reflection Mode)

This is a shorter conversation (about 5 minutes) to capture your immediate thoughts.

*Your first name (so Ray knows who you are)*

### Write Mode (Reflection Form)

- **Your Email (so we can link this to your registration)** — *Placeholder: The one you used to register*
- **Did anything shift for you between the private AI conversation and the group wānanga?**
- **Was there anything you shared with the AI that you would not have said in the room — or something that came up in the room that you would not have told the AI?**
- **Having experienced both, what feels right about conversational AI in vulnerable spaces — and what does not?**
- **Would you use something like this again?** — Yes / No / Maybe
- **Would you recommend this experience to someone you care about?** — Yes / No / Maybe
- **Anything else you want us to know?**

**Button:** Submit Reflections

**Success:**
Ngā mihi nui.
Your reflections have been safely received.
We will send you a summary of insights soon.

**Error:** Unable to save your reflections. Please try again.

---
---

## PAGE 6: PARTICIPATE (participate.astro + ParticipationFlow.jsx)

**Title:** Participate | Mana Ako x Project Rise

# Join the Kōrero

Register, Consent, and Speak.

---

### Step 0: Choose Your Path

## How would you like to take part?

Pick whatever feels right. You can switch anytime.

**Card 1 — Talk to the AI**
10–15 min voice conversation using Lian's voice.

**Card 2 — Fill in a form**
Share your thoughts in writing, in your own time.

**Card 3 — Talk to a person**
30 min kōrero with Lian or Lee. Also available for under 18s.

**Card 4 — Not sure yet**
Leave your details and we'll reach out.

---

### Step 1: Your Details

**Progress:** 1. Details → 2. Consent → 3. Prepare → 4. Kōrero

## Your Details

Kia ora — before we begin, we need a few details. This takes about 60 seconds.

- **First Name \*** — *Placeholder: Enter your first name*
- **Last Name \*** — *Placeholder: Enter your last name*
- **Email Address \*** — *Placeholder: you@example.com*
  - *This is how we will send your wānanga invitation.*
- **Which best describes you?** — Select... / Te reo Māori learner / Te reo Māori speaker or practitioner / Educator or kaiako / Kaupapa Māori practitioner / Technology or AI professional / Researcher or academic / Community member / Other
- **Which cultural identities do you connect with?** — *Placeholder: e.g. Māori, Samoan, Pākehā...*
- **Age Range** — Select... / Under 18 / 18–24 / 25–34 / 35–44 / 45–54 / 55–64 / 65+
- **Where in Aotearoa are you based?** — *Placeholder: e.g. Hamilton, Tai Tokerau*

**Under 18 section (if selected):**
- Parent/Guardian Full Name *
- Parent/Guardian Email *
- Parent/Guardian Phone
- *Because you're under 18, we need a parent or guardian's contact details so we can get their consent before you take part.*

*These details help us understand who is in the room. They are optional — share what feels comfortable. Nothing here affects your ability to participate.*

**Button:** Next Step: Consent

**Errors:**
- Please fill in the required fields (Name & Email).
- Please provide your parent or guardian's name and email.

---

### Step 2: Consent

## Consent

Before we start the kōrero, please read through the following and confirm you are comfortable to proceed. Consent is ongoing — you can change your mind at any time.

#### What this involves
*Summary: 10–15 min voice conversation with an AI using Lian's voice, then an online wānanga.*

You will have a 10 to 15 minute voice conversation with a conversational AI agent. It uses Lian's voice and will ask you about safety, vulnerability, and cultural considerations around conversational AI. After the conversation, you will be invited to an online wānanga on Thursday 26 February, 6.30pm to 8pm NZDT, where we explore these themes as a group.

If at any point during the AI conversation you would prefer to talk to a person instead, you can stop and book a kōrero with Lian or Lee. The same applies in reverse.

#### About the AI
*Summary: This is a tool, not a person. It makes mistakes. That's part of what we're studying.*

This is a conversational AI. It uses Lian's voice, but it is not Lian. It is not a person, a teacher, a therapist, or an authority on anything. It is a tool — and like all tools, it has limitations.

The AI can make mistakes. It may misunderstand what you say, respond in ways that do not quite fit, or miss nuance that a person would catch. It does not hold cultural knowledge the way a person does. It cannot read your body language or your silence. It does not remember you between sessions.

We are not presenting it as something it is not. Part of what this research explores is exactly where AI works and where it falls short — and your experience of those edges is some of the most valuable data we will collect.

#### How your voice is processed
*Summary: Processed by ElevenLabs (US). We've opted out of training. Full terms linked.*

When you speak to the AI agent, your voice and words are processed by ElevenLabs, a US-based voice AI company. Your conversation is sent to their servers in the United States. All data is transferred to and stored in the United States, regardless of your location.

We have opted out of ElevenLabs using your data for AI model training. However, by using the agent, your conversation is subject to ElevenLabs' Terms of Service, which grants them a broad, perpetual license to use conversation data to provide and improve their services. We cannot revoke this license after the fact.

ElevenLabs also reserves the right to moderate conversations for safety purposes, which means their staff or contractors may access your conversation content.

#### How we use your kōrero
*Summary: Anonymised, used in both master's projects, and may inform a public resource.*

Your conversation transcript is stored in ElevenLabs. We download it from there for analysis as part of both Lian's and Lee's master's research projects at AcademyEX. Your registration details are stored separately in Supabase (Sydney, Australia) with row-level security.

All data used in our research will be anonymised — your name and identifying details will be removed before analysis or publication. Anonymised insights and themes from this research may also be used to develop a public-facing resource (such as a report or guide) to share what we have learned about designing conversational AI for vulnerable and culturally significant spaces.

#### Two layers of data control
*Summary: We control the research use. ElevenLabs controls the tech processing.*

**Lian and Lee** control how your conversation content is used for research purposes — what gets analysed and how findings are shared. Your registration data is in Supabase; transcripts are downloaded from ElevenLabs. You can ask us to delete your registration data at any time.

**ElevenLabs** controls the technical processing and storage of your voice recordings on their platform. Their retention and usage policies are governed by their own Terms of Service.

Our research protocols are separate from ElevenLabs' platform policies. You have rights under both.

#### Who sees your responses
*Summary: Lian, Lee, and supervisors. Cultural advisors see de-identified themes only.*

Lian and Lee (the researchers), and our academic supervisors (Felix Scholz and Paula Gair). Cultural advisors may review de-identified themes. All responses are anonymised before analysis — your name will not appear in any published work or public resource unless you specifically request attribution.

#### Your rights
*Summary: Voluntary. Ongoing consent. Withdraw anytime. 18+ for AI.*

- Participation is completely voluntary — and consent is ongoing, not a one-time decision
- You can stop the conversation at any time — just close the browser
- You can switch from the AI to a person, or from a person to the AI, at any point
- You can withdraw your data from our research database up to two weeks after the wānanga by emailing us
- We will delete our copy of your transcript within 3 years of project completion, or earlier at your request
- ElevenLabs retains voice data for up to 3 years after last interaction — we cannot control their retention
- If you are under 18, you can participate with a parent or guardian's consent
- If you prefer not to use AI, you can book a conversation with us directly
- Choosing not to participate has no consequences whatsoever

#### If something comes up
*Summary: Support resources available. You can stop anytime, no explanation needed.*

These conversations can touch on personal experiences of vulnerability, shame, or cultural harm. If anything feels uncomfortable, you are welcome to stop at any time. You do not need to explain why.

If you would like to talk to someone:

**Mental Health Support**
1737 — free call or text, anytime (24/7)
Lifeline — 0800 543 354

**Domestic Violence**
Women's Refuge — 0800 733 843

**Emergency**
111

Lian and Lee are also available if you want to debrief: lianpassmore@gmail.com or leepalamo275@gmail.com

---

**Consent checkboxes:**

1. I understand what this research involves and how my data will be processed, including by ElevenLabs under their Terms of Service
2. I understand my conversation will be recorded, transcribed, and stored for research purposes
3. I understand my participation is voluntary, consent is ongoing, and I can withdraw at any time
4. I understand the AI is a tool with limitations — it is not a person, teacher, or authority
5. I consent to my anonymised insights being used in Lian Passmore's and Lee Palamo's master's research at AcademyEX, and in any public resource developed from this research
6. I confirm I am 18 years or older *(or: I confirm I am under 18 and have provided my parent or guardian's contact details)*
7. I am ready to begin

*By proceeding, you are giving informed consent as described above. You can revisit or change your mind about any part of this at any time. If you have any questions before starting, email lianpassmore@gmail.com or leepalamo275@gmail.com, or book a kōrero with us.*

**Button:** I Agree — Continue

**Error:** Please confirm all consent checkboxes to proceed.

---

### Step 3: Before You Begin

# Before you begin.

#### Honouring the space

This kōrero may touch on things that sit close to the heart — identity, culture, vulnerability, shame. For some people, this kind of conversation naturally sits in a space that deserves care.

If it feels right for you, you are welcome to take a moment before you start — whether that is a karakia, a quiet breath, or simply checking in with yourself. There is no right or wrong way to enter this space. How you begin and end is entirely yours.

#### What you are walking into

In a moment, you will hear Lian's voice. But it is not Lian — it is a conversational AI using her voice. It will introduce itself and guide the conversation. You do not need to prepare anything.

The AI is a tool. It can make mistakes, miss nuance, or respond in ways that feel off. That is okay — noticing those moments is part of what makes your experience valuable to this research.

#### What to notice

As you talk, pay attention to how it feels. Notice where trust forms or breaks down. Notice where the AI feels helpful — and where it feels unsafe or insufficient. You do not need to analyse this in the moment. Just let yourself notice.

This works best in a quiet space with headphones. The conversation runs about 10 to 15 minutes. You can say as much or as little as you like. There are no wrong answers — we are exploring, not testing.

#### If you want to stop

If you want to stop at any time, just close the page. If you decide you would rather talk to a person instead, you can reach Lian or Lee at lianpassmore@gmail.com or leepalamo275@gmail.com, or book a time.

**Button:** Start the kōrero

---

### Step 4: Kōrero

## Kōrero with the AI Agent

*[Animated orb + conversation interface]*

**Link:** I have finished the conversation →

---

### Step 5: Post-Conversation

## Ngā mihi — thank you.

Your kōrero matters. What you have just shared will help shape how we think about designing conversational AI for vulnerable spaces.

#### Before you go — two quick questions

- **Would you use something like this again?** — Yes / No / Maybe
- **Would you recommend this experience to someone you care about?** — Yes / No / Maybe
- **Is there anything else sitting with you right now?** *(Optional)*

**Button:** Submit

#### What happens next

Check your email — we have sent you an invitation to the online wānanga on **Thursday 26 February, 6.30pm to 8pm NZDT**. That is where we take everything that has been shared in these individual conversations and explore it together as a group. The wānanga is a culturally grounded space to sit with what came up and make sense of it alongside others.

You will also receive a reminder the day before, and an hour before we start.

#### Want to switch paths?

If that conversation made you want to talk to a person, you can book a kōrero with Lian or Lee anytime.
→ Book a kōrero →

**Can't make the wānanga?** That is okay. Your conversation still contributes to the research and we value it. We will send you a summary of what we learned after the wānanga.

**Want to talk to us?** If anything came up during the conversation that you would like to discuss — or if you just want to say hi before the wānanga — reach out anytime: lianpassmore@gmail.com or leepalamo275@gmail.com

**Link:** Return to Home

---

### Step 6: Contact Me

## We'll reach out to you

Leave your details and we'll get in touch to find the right way for you to take part.

- **First Name \***
- **Last Name \***
- **Email Address \***
- **Phone Number**
- **How would you like us to contact you? \*** — Email / Call / Text

**Button:** Send my details

**Success:**
Ngā mihi — we'll be in touch.
We've got your details and will reach out by [method] soon.

**Link:** Return to Home

---

### Step 7: Written Form

## Your kōrero, in writing

Answer as many or as few as you like. There are no right or wrong answers — we are interested in your honest experience and instincts. 3–5 sentences per question is ideal, but write as much or as little as feels right.

**Ice-breaker:** How are you feeling about this experience?
Comfortable / A bit nervous / Curious / Sceptical / Other

**Questions:**

1. Think about a time you wanted to share something personal or important in a digital space (online, an app, a form). What was that experience like? What made it feel safe or unsafe?

2. Imagine someone talking to an AI about something deeply personal — their relationship, something tied to their identity, or something painful. What's your gut reaction to that idea? Where would you draw the line?

3. Some knowledge and experiences feel sacred or protected — things that shouldn't just become "data." In te ao Māori, this is described as tapu (sacred/protected) vs noa (ordinary/freely shared). How do you think about what should stay protected vs what can be shared with or through technology?

4. If researchers are building AI for vulnerable conversations (relationship support, language learning, cultural spaces), what must they absolutely get right? What should they never forget?

**Button:** Submit my answers

**Success:**
Ngā mihi — thank you.
Your written kōrero matters. What you have shared will help shape how we think about designing conversational AI for vulnerable spaces.

---
---

## CRISIS SUPPORT MODAL (all pages)

**Trigger button:** Need Support? (!)

### Support Resources

These conversations can touch on personal experiences of vulnerability, shame, or cultural harm. If anything feels uncomfortable, you are welcome to stop at any time.

**Mental Health Support**
- **1737** — Free call or text, anytime (24/7)
- **Lifeline** — 0800 543 354

**Domestic Violence**
- **Women's Refuge** — 0800 733 843

**Emergency**
- **111**

*Lian and Lee are also available if you want to debrief: lianpassmore@gmail.com or leepalamo275@gmail.com*

**Button:** Return to Website

---
---

## AI CONVERSATION UI (AgentConversation.jsx)

**Status labels:** Tap to begin / Listening / Speaking / Connecting...

**Warning:** This is an AI tool, not a person. It can make mistakes, miss nuance, or get things wrong.

**Buttons:** Mute / Unmute | End Call

**Errors:**
- Unable to connect to the agent. Please try refreshing the page.
- Microphone access denied. Please check your browser settings and try again.
